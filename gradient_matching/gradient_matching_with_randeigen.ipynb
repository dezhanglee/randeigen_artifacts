{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c73553-21e2-460c-a746-66ef3af21f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "from art.attacks.poisoning import *\n",
    "\n",
    "\n",
    "\n",
    "device=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "878453c8-6274-444b-94f2-35a340de0a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: F.pad(\n",
    "            Variable(x.unsqueeze(0), requires_grad=False),\n",
    "            (4, 4, 4, 4), mode='reflect').data.squeeze()),\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomCrop(32),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, #batch_size=batch_size,\n",
    "                                         )\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, #batch_size=batch_size,\n",
    "                                        )\n",
    "                                         #shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc4e6fb2-3a38-445e-a848-c5e03082a67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dezhang/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dezhang/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "net = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "net.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 10)\n",
    ")\n",
    "net = net.to(device)\n",
    "# params (LR) recommended in paper\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb1bbf94-b9fd-4e61-bc92-880ecf2b1e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from art.estimators.classification import PyTorchClassifier\n",
    "# classifier = PyTorchClassifier(\n",
    "#     model=net,\n",
    "#     clip_values=(0, 1),\n",
    "#     loss=criterion,\n",
    "#     optimizer=optimizer,\n",
    "#     input_shape=(3,32,32),\n",
    "#     nb_classes=10,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf138a78-25a8-4071-a813-ef9586138f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gma = GradientMatchingAttack(classifier, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec1c59b6-59c8-4189-a083-23e370eaf208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision.transforms as T\n",
    "directory = os.fsencode(\"poisoned_cifar10/train/cat/\")\n",
    "poisoned_imgs = []\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".png\"): \n",
    "        a=torchvision.io.read_image(\"poisoned_cifar10/train/cat/\"+filename)\n",
    "        b=T.ToPILImage()(a) \n",
    "        poisoned_imgs.append(transform(b))\n",
    "        continue\n",
    "    else:\n",
    "        continue\n",
    "poisoned_labels = torch.Tensor([3 for i in poisoned_imgs]).to(device)\n",
    "poisoned_imgs = torch.stack(poisoned_imgs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "310bd836-c14a-460a-a490-88361c66566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision.transforms as T\n",
    "directory = os.fsencode(\"poisoned_cifar10/targets/cat/\")\n",
    "poisoned_imgs_test = []\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".png\"): \n",
    "        a=torchvision.io.read_image(\"poisoned_cifar10/targets/cat/\"+filename)\n",
    "        b=T.ToPILImage()(a) \n",
    "        poisoned_imgs_test.append(transform(b))\n",
    "        continue\n",
    "    else:\n",
    "        continue\n",
    "poisoned_labels_test = torch.Tensor([1 for i in poisoned_imgs_test]).to(device)\n",
    "poisoned_imgs_test = torch.stack(poisoned_imgs_test*2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "380618aa-677c-4112-9290-4ec829ac9c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.Tensor(np.array([i[0][0] for i in trainloader])).to(device)\n",
    "y_train = torch.Tensor(np.array([i[1][0] for i in trainloader])).type(torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "588a58f8-630e-42aa-b772-33c6c5537f4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # train a base model with 20% of the training data, then we fine tune on the poisoned data\n",
    "\n",
    "# n_epoch = 100\n",
    "# batch_size = 512\n",
    "# train_set_size = len(x_train)//2\n",
    "# for _ in range(n_epoch):\n",
    "#     print(\"epoch \" + str(_))\n",
    "    \n",
    "#     for i in range(0,train_set_size,batch_size):\n",
    "\n",
    "    \n",
    "#         feature = x_train[i:i+batch_size]\n",
    "#         # feature.requires_grad = True  ### CRUCIAL L?INE !!!\n",
    "#         target = y_train[i:i+batch_size]\n",
    "#         optimizer.zero_grad()\n",
    "#         output = net(feature)\n",
    "#         loss = criterion(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "\n",
    "#         # non car\n",
    "#         train_prob = net(x_train[train_set_size:])\n",
    "#         train_pred = torch.argmax(train_prob, dim=-1)\n",
    "#         n_correct = torch.sum(train_pred == y_train[train_set_size:])\n",
    "#         # print(train_pred)\n",
    "#         print(\"TEST ACC:\", float(n_correct/train_set_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9449ff-ef18-492b-983a-9380939ca173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "975b34cf-55a8-433a-a0d5-17348ac7b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add poisoned data\n",
    "\n",
    "x_train_poisoned = torch.concat([x_train, poisoned_imgs])\n",
    "y_train_poisoned = torch.concat([y_train, poisoned_labels]).type(torch.long).to(device)\n",
    "\n",
    "# x_train_poisoned=x_train\n",
    "# y_train_poisoned = y_train\n",
    "\n",
    "x_train_car = torch.stack([x_train_poisoned[i] for i in range(len(x_train_poisoned)) if y_train_poisoned[i] == 1]).to(device)\n",
    "x_train_not_car = torch.stack([x_train_poisoned[i] for i in range(len(x_train_poisoned)) if y_train_poisoned[i] != 1]).to(device)\n",
    "y_train_not_car = torch.stack([y_train_poisoned[i] for i in range(len(x_train_poisoned)) if y_train_poisoned[i] != 1]).to(device)\n",
    "# import random\n",
    "# random.seed(0)\n",
    "# shuffle_idx = random.shuffle([i for i in range(len(x_train_poisoned))])\n",
    "# x_train_poisoned = x_train_poisoned[shuffle_idx]\n",
    "# y_train_poisoned = y_train_poisoned[shuffle_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382b0cd3-4702-4e1f-9286-01cb8997759f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72592e26-9881-4333-9f2f-e0963e1bfa05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50500, 3, 32, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_poisoned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dbf6fb6-2e0b-44a5-907e-675fcb55f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test acc\n",
    "x_test = torch.stack([i[0][0] for i in testloader]).to(device)\n",
    "y_test = torch.stack([i[1][0] for i in testloader]).type(torch.long).to(device)\n",
    "# y_train_poisoned = torch.concat([y_train, poisoned_labels])[0].type(torch.long).to(device)\n",
    "\n",
    "x_test_car = torch.stack([x_test[i] for i in range(len(x_test)) if y_test[i] == 2]).to(device)\n",
    "x_test_not_car = torch.stack([x_test[i] for i in range(len(x_test)) if y_test[i] != 2]).to(device)\n",
    "y_test_not_car = torch.stack([y_test[i] for i in range(len(x_test)) if y_test[i] != 2]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c4eacdd-8175-4a6b-8272-299780094959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 3, 32, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_car.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88e44fd5-6f84-40dc-ab8f-e5b9ee6fc6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified version of randeigen\n",
    "# instead of giving a robust aggregate over the sample, we return the samples which are removed\n",
    "# take in a set of inputs and their corresponding gradient\n",
    "# output the clean inputs \n",
    "import math\n",
    "\n",
    "def power_iteration(mat, iterations, device):\n",
    "    dim = mat.shape[0]\n",
    "    u = torch.randn((dim, 1)).to(device)\n",
    "    for _ in range(iterations):\n",
    "        u = mat @ u / torch.linalg.norm(mat @ u) \n",
    "    eigenvalue = u.T @ mat @ u\n",
    "    return eigenvalue, u\n",
    "\n",
    "# return the index of the clean samples\n",
    "def randomized_agg_forced(data, eps_poison=0.2, eps_jl=0.1, eps_pow = 0.1, seed=12):\n",
    "    n = int(data.shape[0])\n",
    "    feature_shape = data[0].shape\n",
    "    n_dim = int(np.prod(np.array(feature_shape)))\n",
    "    res =  _randomized_agg(data, eps_poison, eps_jl, eps_pow, 1, 10**-5, forced=True, seed=seed) # set threshold for convergence as 1*10**-5 (i.e. float point error)\n",
    "    return res\n",
    "\n",
    "def _randomized_agg(data, eps_poison=0.2, eps_jl=0.1, eps_pow = 0.1, threshold = 20, clean_eigen = 10**-5, forced=False, seed=None):\n",
    "    if seed:\n",
    "        torch.manual_seed(seed)\n",
    "    \n",
    "    n = int(data.shape[0])\n",
    "    data = data.to(device)\n",
    "    \n",
    "    d = int(math.prod(data[0].shape))\n",
    "    data_flatten = data.reshape(n, d)\n",
    "    data_mean = torch.mean(data_flatten, dim=0)\n",
    "    data_sd = torch.std(data_flatten, dim=0)\n",
    "    data_norm = (data_flatten - data_mean)/data_sd\n",
    "    \n",
    "    k = min(int(math.log(d)//eps_jl**2), d)\n",
    "    \n",
    "    A = torch.randn((d, k)).to(device)\n",
    "    A = A/(k**0.5)\n",
    "\n",
    "    Y = data_flatten @ A # n times k\n",
    "    Y = Y.to(device)\n",
    "    # print(k)\n",
    "    power_iter_rounds = int(- math.log(4*k)/(2*math.log(1-eps_pow)))\n",
    "    clean_eigen = clean_eigen * d/k\n",
    "    old_eigenvalue = None\n",
    "    for _ in range(max(int(eps_poison*n), 10)):\n",
    "        Y_mean = torch.mean(Y, dim=0)\n",
    "        # Y = (Y - Y_mean)\n",
    "        Y_cov = torch.cov(Y.T)\n",
    "        Y_sq = Y_cov\n",
    "        # print(Y_sq)\n",
    "        eigenvalue, eigenvector = power_iteration(Y_sq, power_iter_rounds, device)\n",
    "\n",
    "        proj_Y = torch.abs(Y @ eigenvector )\n",
    "        proj_Y = torch.flatten(proj_Y)\n",
    "        if forced and old_eigenvalue and abs(old_eigenvalue - eigenvalue) < 10**-5:\n",
    "            # print('converge')\n",
    "            break\n",
    "\n",
    "        if len(proj_Y) < eps_poison*n or sum([i > 0.5 for i in proj_Y/torch.max(proj_Y)]) > len(proj_Y)*(1-2*eps_poison):\n",
    "            # print('new_criteria')\n",
    "            break \n",
    "        old_eigenvalue = eigenvalue\n",
    "        \n",
    "        uniform_rand = torch.rand(proj_Y.shape).to(device)\n",
    "        kept_idx = uniform_rand > (proj_Y/torch.max(proj_Y))\n",
    "        Y = Y[kept_idx]\n",
    "        data = data[kept_idx]\n",
    "    return kept_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ff1d0dd-87fc-4f55-bb39-61d210848df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "attack fail\n",
      "TRAIN ACC:  0.7732999920845032 TEST ACC:  0.6818999648094177\n",
      "epoch 1\n",
      "attack fail\n",
      "TRAIN ACC:  0.7741199731826782 TEST ACC:  0.6821999549865723\n",
      "epoch 2\n",
      "attack fail\n",
      "TRAIN ACC:  0.7749599814414978 TEST ACC:  0.6823999881744385\n",
      "epoch 3\n",
      "attack fail\n",
      "TRAIN ACC:  0.7754799723625183 TEST ACC:  0.682699978351593\n",
      "epoch 4\n",
      "attack fail\n",
      "TRAIN ACC:  0.7763800024986267 TEST ACC:  0.6827999949455261\n",
      "epoch 5\n",
      "attack fail\n",
      "TRAIN ACC:  0.776919960975647 TEST ACC:  0.6834999918937683\n",
      "epoch 6\n",
      "attack fail\n",
      "TRAIN ACC:  0.7777999639511108 TEST ACC:  0.6836000084877014\n",
      "epoch 7\n",
      "attack fail\n",
      "TRAIN ACC:  0.778659999370575 TEST ACC:  0.6836999654769897\n",
      "epoch 8\n",
      "attack fail\n",
      "TRAIN ACC:  0.7795199751853943 TEST ACC:  0.6841999888420105\n",
      "epoch 9\n",
      "attack fail\n",
      "TRAIN ACC:  0.7804399728775024 TEST ACC:  0.6847000122070312\n",
      "epoch 10\n",
      "attack fail\n",
      "TRAIN ACC:  0.7813000082969666 TEST ACC:  0.6847999691963196\n",
      "epoch 11\n",
      "attack fail\n",
      "TRAIN ACC:  0.7820599675178528 TEST ACC:  0.6847999691963196\n",
      "epoch 12\n",
      "attack fail\n",
      "TRAIN ACC:  0.7826600074768066 TEST ACC:  0.6848999857902527\n",
      "epoch 13\n",
      "attack fail\n",
      "TRAIN ACC:  0.7835800051689148 TEST ACC:  0.6847999691963196\n",
      "epoch 14\n",
      "attack fail\n",
      "TRAIN ACC:  0.7839799523353577 TEST ACC:  0.6850000023841858\n",
      "epoch 15\n",
      "attack fail\n",
      "TRAIN ACC:  0.7846800088882446 TEST ACC:  0.6854000091552734\n",
      "epoch 16\n",
      "attack fail\n",
      "TRAIN ACC:  0.7853399515151978 TEST ACC:  0.6854999661445618\n",
      "epoch 17\n",
      "attack fail\n",
      "TRAIN ACC:  0.786139965057373 TEST ACC:  0.6857999563217163\n",
      "epoch 18\n",
      "attack fail\n",
      "TRAIN ACC:  0.7869399785995483 TEST ACC:  0.6866999864578247\n",
      "epoch 19\n",
      "attack fail\n",
      "TRAIN ACC:  0.7878599762916565 TEST ACC:  0.6862999796867371\n",
      "epoch 20\n",
      "attack fail\n",
      "TRAIN ACC:  0.7887399792671204 TEST ACC:  0.6861000061035156\n",
      "epoch 21\n",
      "attack fail\n",
      "TRAIN ACC:  0.7893199920654297 TEST ACC:  0.6863999962806702\n",
      "epoch 22\n",
      "attack fail\n",
      "TRAIN ACC:  0.7901600003242493 TEST ACC:  0.6862999796867371\n",
      "epoch 23\n",
      "attack fail\n",
      "TRAIN ACC:  0.7908799648284912 TEST ACC:  0.6858999729156494\n",
      "epoch 24\n",
      "attack fail\n",
      "TRAIN ACC:  0.7915199995040894 TEST ACC:  0.6864999532699585\n",
      "epoch 25\n",
      "attack fail\n",
      "TRAIN ACC:  0.7924000024795532 TEST ACC:  0.6866999864578247\n",
      "epoch 26\n",
      "attack fail\n",
      "TRAIN ACC:  0.7932199835777283 TEST ACC:  0.6869999766349792\n",
      "epoch 27\n",
      "attack fail\n",
      "TRAIN ACC:  0.7937799692153931 TEST ACC:  0.6872000098228455\n",
      "epoch 28\n",
      "attack fail\n",
      "TRAIN ACC:  0.7948399782180786 TEST ACC:  0.6877999901771545\n",
      "epoch 29\n",
      "attack fail\n",
      "TRAIN ACC:  0.7956199645996094 TEST ACC:  0.687999963760376\n",
      "epoch 30\n",
      "attack fail\n",
      "TRAIN ACC:  0.7962999939918518 TEST ACC:  0.6883999705314636\n",
      "epoch 31\n",
      "attack fail\n",
      "TRAIN ACC:  0.7969399690628052 TEST ACC:  0.6880999803543091\n",
      "epoch 32\n",
      "attack fail\n",
      "TRAIN ACC:  0.7975199818611145 TEST ACC:  0.6884999871253967\n",
      "epoch 33\n",
      "attack fail\n",
      "TRAIN ACC:  0.7981199622154236 TEST ACC:  0.6884999871253967\n",
      "epoch 34\n",
      "attack fail\n",
      "TRAIN ACC:  0.7987399697303772 TEST ACC:  0.6888999938964844\n",
      "epoch 35\n",
      "attack fail\n",
      "TRAIN ACC:  0.7997999787330627 TEST ACC:  0.6888999938964844\n",
      "epoch 36\n",
      "attack fail\n",
      "TRAIN ACC:  0.8003999590873718 TEST ACC:  0.6883999705314636\n",
      "epoch 37\n",
      "attack fail\n",
      "TRAIN ACC:  0.8012199997901917 TEST ACC:  0.6890000104904175\n",
      "epoch 38\n",
      "attack fail\n",
      "TRAIN ACC:  0.8017999529838562 TEST ACC:  0.6894999742507935\n",
      "epoch 39\n",
      "attack fail\n",
      "TRAIN ACC:  0.8026799559593201 TEST ACC:  0.6897000074386597\n",
      "epoch 40\n",
      "attack fail\n",
      "TRAIN ACC:  0.8034999966621399 TEST ACC:  0.6897000074386597\n",
      "epoch 41\n",
      "attack fail\n",
      "TRAIN ACC:  0.8042999505996704 TEST ACC:  0.6899999976158142\n",
      "epoch 42\n",
      "attack fail\n",
      "TRAIN ACC:  0.8049799799919128 TEST ACC:  0.6898999810218811\n",
      "epoch 43\n",
      "attack fail\n",
      "TRAIN ACC:  0.8055799603462219 TEST ACC:  0.6905999779701233\n",
      "epoch 44\n",
      "attack fail\n",
      "TRAIN ACC:  0.8060599565505981 TEST ACC:  0.6911999583244324\n",
      "epoch 45\n",
      "attack fail\n",
      "TRAIN ACC:  0.806879997253418 TEST ACC:  0.6912999749183655\n",
      "epoch 46\n",
      "attack fail\n",
      "TRAIN ACC:  0.807699978351593 TEST ACC:  0.69159996509552\n",
      "epoch 47\n",
      "attack fail\n",
      "TRAIN ACC:  0.80867999792099 TEST ACC:  0.6917999982833862\n",
      "epoch 48\n",
      "attack fail\n",
      "TRAIN ACC:  0.8093999624252319 TEST ACC:  0.6919999718666077\n",
      "epoch 49\n",
      "attack fail\n",
      "TRAIN ACC:  0.8100399971008301 TEST ACC:  0.6920999884605408\n",
      "epoch 50\n",
      "attack fail\n",
      "TRAIN ACC:  0.8104599714279175 TEST ACC:  0.6922000050544739\n",
      "epoch 51\n",
      "attack fail\n",
      "TRAIN ACC:  0.8113600015640259 TEST ACC:  0.69159996509552\n",
      "epoch 52\n",
      "attack fail\n",
      "TRAIN ACC:  0.8119800090789795 TEST ACC:  0.6916999816894531\n",
      "epoch 53\n",
      "attack fail\n",
      "TRAIN ACC:  0.8125799894332886 TEST ACC:  0.6918999552726746\n",
      "epoch 54\n",
      "attack fail\n",
      "TRAIN ACC:  0.8132799863815308 TEST ACC:  0.6920999884605408\n",
      "epoch 55\n",
      "attack fail\n",
      "TRAIN ACC:  0.8137799501419067 TEST ACC:  0.6922999620437622\n",
      "epoch 56\n",
      "attack fail\n",
      "TRAIN ACC:  0.8143599629402161 TEST ACC:  0.6926000118255615\n",
      "epoch 57\n",
      "attack fail\n",
      "TRAIN ACC:  0.8150999546051025 TEST ACC:  0.6929000020027161\n",
      "epoch 58\n",
      "attack fail\n",
      "TRAIN ACC:  0.8157399892807007 TEST ACC:  0.6929000020027161\n",
      "epoch 59\n",
      "attack fail\n",
      "TRAIN ACC:  0.8162800073623657 TEST ACC:  0.6926999688148499\n",
      "epoch 60\n",
      "attack fail\n",
      "TRAIN ACC:  0.8168599605560303 TEST ACC:  0.6926999688148499\n",
      "epoch 61\n",
      "attack fail\n",
      "TRAIN ACC:  0.8175399899482727 TEST ACC:  0.6930999755859375\n",
      "epoch 62\n",
      "attack fail\n",
      "TRAIN ACC:  0.8182599544525146 TEST ACC:  0.693399965763092\n",
      "epoch 63\n",
      "attack fail\n",
      "TRAIN ACC:  0.8186999559402466 TEST ACC:  0.6935999989509583\n",
      "epoch 64\n",
      "attack fail\n",
      "TRAIN ACC:  0.8193599581718445 TEST ACC:  0.6936999559402466\n",
      "epoch 65\n",
      "attack fail\n",
      "TRAIN ACC:  0.8198399543762207 TEST ACC:  0.6941999793052673\n",
      "epoch 66\n",
      "attack fail\n",
      "TRAIN ACC:  0.8203199505805969 TEST ACC:  0.694599986076355\n",
      "epoch 67\n",
      "attack fail\n",
      "TRAIN ACC:  0.8209999799728394 TEST ACC:  0.6944999694824219\n",
      "epoch 68\n",
      "attack fail\n",
      "TRAIN ACC:  0.8217799663543701 TEST ACC:  0.6948999762535095\n",
      "epoch 69\n",
      "attack fail\n",
      "TRAIN ACC:  0.8224200010299683 TEST ACC:  0.6947999596595764\n",
      "epoch 70\n",
      "attack fail\n",
      "TRAIN ACC:  0.8226999640464783 TEST ACC:  0.6949999928474426\n",
      "epoch 71\n",
      "attack fail\n",
      "TRAIN ACC:  0.8235599994659424 TEST ACC:  0.6948999762535095\n",
      "epoch 72\n",
      "attack fail\n",
      "TRAIN ACC:  0.8240999579429626 TEST ACC:  0.6948999762535095\n",
      "epoch 73\n",
      "attack fail\n",
      "TRAIN ACC:  0.8246399760246277 TEST ACC:  0.6951999664306641\n",
      "epoch 74\n",
      "attack fail\n",
      "TRAIN ACC:  0.8253999948501587 TEST ACC:  0.6954999566078186\n",
      "epoch 75\n",
      "attack fail\n",
      "TRAIN ACC:  0.8260999917984009 TEST ACC:  0.6954999566078186\n",
      "epoch 76\n",
      "attack fail\n",
      "TRAIN ACC:  0.8265799880027771 TEST ACC:  0.6953999996185303\n",
      "epoch 77\n",
      "attack fail\n",
      "TRAIN ACC:  0.8272199630737305 TEST ACC:  0.6954999566078186\n",
      "epoch 78\n",
      "attack fail\n",
      "TRAIN ACC:  0.8277599811553955 TEST ACC:  0.6952999830245972\n",
      "epoch 79\n",
      "attack fail\n",
      "TRAIN ACC:  0.8285999894142151 TEST ACC:  0.6955999732017517\n",
      "epoch 80\n",
      "attack fail\n",
      "TRAIN ACC:  0.8294000029563904 TEST ACC:  0.6951999664306641\n",
      "epoch 81\n",
      "attack fail\n",
      "TRAIN ACC:  0.8299799561500549 TEST ACC:  0.6953999996185303\n",
      "epoch 82\n",
      "attack fail\n",
      "TRAIN ACC:  0.8307399749755859 TEST ACC:  0.6953999996185303\n",
      "epoch 83\n",
      "attack fail\n",
      "TRAIN ACC:  0.8315799832344055 TEST ACC:  0.6954999566078186\n",
      "epoch 84\n",
      "attack fail\n",
      "TRAIN ACC:  0.8322599530220032 TEST ACC:  0.6958000063896179\n",
      "epoch 85\n",
      "attack fail\n",
      "TRAIN ACC:  0.8329799771308899 TEST ACC:  0.6959999799728394\n",
      "epoch 86\n",
      "attack fail\n",
      "TRAIN ACC:  0.8336399793624878 TEST ACC:  0.6959999799728394\n",
      "epoch 87\n",
      "attack fail\n",
      "TRAIN ACC:  0.8342599868774414 TEST ACC:  0.6959999799728394\n",
      "epoch 88\n",
      "attack fail\n",
      "TRAIN ACC:  0.8350200057029724 TEST ACC:  0.6955999732017517\n",
      "epoch 89\n",
      "attack fail\n",
      "TRAIN ACC:  0.8357599973678589 TEST ACC:  0.6958000063896179\n",
      "epoch 90\n",
      "attack fail\n",
      "TRAIN ACC:  0.8363800048828125 TEST ACC:  0.6958000063896179\n",
      "epoch 91\n",
      "attack fail\n",
      "TRAIN ACC:  0.8371999859809875 TEST ACC:  0.6958000063896179\n",
      "epoch 92\n",
      "attack fail\n",
      "TRAIN ACC:  0.8379600048065186 TEST ACC:  0.6956999897956848\n",
      "epoch 93\n",
      "attack fail\n",
      "TRAIN ACC:  0.8385599851608276 TEST ACC:  0.6956999897956848\n",
      "epoch 94\n",
      "attack fail\n",
      "TRAIN ACC:  0.838979959487915 TEST ACC:  0.6955999732017517\n",
      "epoch 95\n",
      "attack fail\n",
      "TRAIN ACC:  0.8394399881362915 TEST ACC:  0.6958999633789062\n",
      "epoch 96\n",
      "attack fail\n",
      "TRAIN ACC:  0.8402599692344666 TEST ACC:  0.6954999566078186\n",
      "epoch 97\n",
      "attack fail\n",
      "TRAIN ACC:  0.8407999873161316 TEST ACC:  0.6960999965667725\n",
      "epoch 98\n",
      "attack fail\n",
      "TRAIN ACC:  0.8416399955749512 TEST ACC:  0.6962999701499939\n",
      "epoch 99\n",
      "attack fail\n",
      "TRAIN ACC:  0.8421799540519714 TEST ACC:  0.696399986743927\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "n_epoch = 100\n",
    "batch_size = 2048\n",
    "for _ in range(n_epoch):\n",
    "    print(\"epoch \" + str(_))\n",
    "    for i in range(0,len(x_train_poisoned),batch_size):\n",
    "\n",
    "        net_copy = copy.deepcopy(net)\n",
    "        feature = x_train_poisoned[i:i+batch_size]\n",
    "        feature.requires_grad = True  ### CRUCIAL LINE !!!\n",
    "        target = y_train_poisoned[i:i+batch_size]\n",
    "        optimizer.zero_grad()\n",
    "        output = net_copy(feature)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # removing the outliers\n",
    "        kept_idx = randomized_agg_forced(feature.grad.flatten(start_dim=-1))\n",
    "        # print(kept_idx.shape)\n",
    "        kept_idx = [i for i in range(len(kept_idx)) if kept_idx[i]]\n",
    "        # print(len(feature) - len(kept_idx), \" entries dropped\")\n",
    "        \n",
    "        feature = x_train_poisoned[i:i+batch_size][kept_idx]\n",
    "        target = y_train_poisoned[i:i+batch_size][kept_idx]\n",
    "        optimizer.zero_grad()\n",
    "        output = net(feature)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        pred_class_poison = torch.argmax(net(poisoned_imgs_test), dim=-1)\n",
    "        #adding the [0] here because for some reason torch wont accept a single input. \n",
    "        #poisoned_imgs_test contains two copies of the poisoned image\n",
    "        # print(\"PREDICTED CLASS\"pred_class_poison[0] )\n",
    "        if pred_class_poison[0] == 3:\n",
    "            print(\"attack succeed\")\n",
    "        else:\n",
    "            print(\"attack fail\")\n",
    "\n",
    "        train_acc = torch.sum(torch.argmax(net(x_train), dim=-1) == y_train)/len(y_train)\n",
    "        test_acc = torch.sum(torch.argmax(net(x_test), dim=-1) == y_test)/len(y_test)\n",
    "        print(\"TRAIN ACC: \", float(train_acc), \"TEST ACC: \", float(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f490938d-0133-410a-af72-de5f68312ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
